---
title: "Selecting experimental stimuli in `R`"
date: November 29, 2019
author: Martin Papenberg
output:
  html_document:
    df_print: kable
---

```{r, include = FALSE}

library(knitr)
library(dplyr)
knitr::opts_chunk$set(warning = FALSE) # echo = FALSE
options(scipen = 999, digits = 2)

knit_print.matrix = function(x, ...) {
    res = paste(c("", "", kable(x)), collapse = "\n")
    asis_output(res)
}
registerS3method("knit_print", "matrix", knit_print.matrix)

```

I spent the better part of the last year working on anticlustering, a 
methodology to select stimuli for experiments in psychology. The work 
culminated in the the `R` package 
[`anticlust`](https://github.com/m-Py/anticlust) and the manuscript 
»[Using anticlustering to partition a stimulus pool into equivalent 
parts](https://psyarxiv.com/3razc/)« 

I was made aware of another `R` package that was also designed to select 
stimuli for experiments: 
[`LexOPS`](https://github.com/JackEdTaylor/LexOPS/). Interestingly, both 
packages were first uploaded to Github on October 25, 2018.

In this post I compare the results of the two packages by applying each 
to three data sets that vary in size from very large to rather small.

## Example 1: Large data set `lexops`

First, let's load the packages:

```{r}
library(LexOPS)
library(anticlust)
library(dplyr)
```

We start by using a data set that is built into the `lexops`:

```{r}
head(lexops)
nrow(lexops)
```

We now reproduce the the first example on the [package 
website](https://jackedtaylor.github.io/LexOPSdocs/the-generate-pipeline.html).
In this example, we extract two sets of stimuli each having 25 elements 
from the entire pool of stimuli. The stimuli should differ on 
`CNC.Brysbaert` but be similar on `Length` and `Zipf.SUBTLEX_UK`; for 
more information on the variables we use for stimulus selection, follow 
the link above. 

```{r}

stim <- lexops %>%
  subset(PK.Brysbaert >= 0.9) %>%
  split_by(CNC.Brysbaert, 1:2 ~ 4:5) %>%
  split_by(BG.SUBTLEX_UK, 0:0.003 ~ 0.009:0.013) %>%
  control_for(Length, 0:0) %>%
  control_for(Zipf.SUBTLEX_UK, -0.2:0.2) %>%
  generate(n = 25) %>%
  long_format()
```

We obtain a table like this:

```{r}
head(stim)
```

To validate the usefulness of the output, let's check out the means and 
standard deviations of the variables that were considered, using the 
function `mean_sd_tab()` from the `anticlust` package.

```{r}
# Compare descriptive statistics by set:
mean_sd_tab(
  stim[, c("CNC.Brysbaert", "BG.SUBTLEX_UK", "Length", "Zipf.SUBTLEX_UK")], 
  stim$condition
)
```

In brackets, we have the standard deviations by set, and before that the 
mean values. As shown, the word sets are quite well balanced on `Length` 
and `Zipf.SUBTLEX_UK`, and quite dissimilar with regard to 
`CNC.Brysbaert` and `BG.SUBTLEX_UK`. That is good, because it is what we 
want!

Let's do the same using the `anticlust` package:[^1]

[^1]: Currently, you need to install the development version for this 
functionality, see the vignette 
[here](../anticlust/stimulus-selection.html)

```{r}

# First, I subset the data and recode variables
stim <- subset(lexops, PK.Brysbaert >= 0.9)
# Code boundaries for the independent variables
stim <- within(lexops, {
  CNC <- ifelse(CNC.Brysbaert >= 1 & CNC.Brysbaert <= 2, "CNC-low", NA)
  CNC <- ifelse(CNC.Brysbaert >= 4 & CNC.Brysbaert <= 5, "CNC-high", CNC)
  BG  <- ifelse(BG.SUBTLEX_UK >= 0 & BG.SUBTLEX_UK <= 0.003, "BG-low", NA)
  BG  <- ifelse(BG.SUBTLEX_UK >= 0.009 & BG.SUBTLEX_UK <= 0.013, "BG-high", BG)
})

# Remove NA values
stim <- subset(stim, !is.na(CNC) & !is.na(BG) & !is.na(Length) & !is.na(Zipf.SUBTLEX_UK))

# Match the conditions based on covariates
stim$matches <- matching(
  subset(stim, select = c(Length, Zipf.SUBTLEX_UK)), 
  match_between = subset(stim, select = c(BG, CNC)),
  match_extreme_first = FALSE
)

# Matches are numbered by achieved similarity. Good matches:
subset(stim, matches == 1, c(string, Length, Zipf.SUBTLEX_UK, BG, CNC, matches))
subset(stim, matches == 2, c(string, Length, Zipf.SUBTLEX_UK, BG, CNC, matches))

# Select the 25 best matches:
final_selection <- subset(stim, matches <= 25)


# Check quality of the selection:
mean_sd_tab(
  final_selection[, c("CNC.Brysbaert", "BG.SUBTLEX_UK", "Length", "Zipf.SUBTLEX_UK")], 
  paste(final_selection$BG, final_selection$CNC)
)

```

The `anticlust` package uses a methodology called 
min-max-anticlustering[^minmax]---it maximizes differerences with regard 
to independent variables while simultaneously minizimizing differences 
with regard to covariates. 

[^minmax]: This method still has to be documented thoroughly -- I am 
working on it.

The results show that the the word sets are quite well balanced on 
`Length` and `Zipf.SUBTLEX_UK`, while they are different with regard to 
`CNC.Brysbaert` and `BG.SUBTLEX_UK`. It seems that `anticlust` ensured 
covariate similarity with regard to `Zipf.SUBTLEX_UK` a little more 
strictlythan `LexOPS`, but overall the results for both packages are 
very similar.

## Example 2: Medium sized data set `oasis`

Next, I use a stimulus set describing 900 images on the dimensions 
valence, arousal and beauty (I also use this data set in the 
[`anticlust` vignette for stimulus 
selection](../anticlust/stimulus-selection.html)). I select three sets 
each consisting of 40 stimuli. I have a slightly different goal than 
before: I wish to create sets that are as similar as possible with 
regard to **all** variables under considerations; I do not vary an 
independent variable between sets. This is what the original 
anticlustering accomplishes---it creates sets that are as similar as 
possible. 

Again, I start with the `LexOPS` package. To ensure that three sets are 
created without having an independent variable, I have to use the 
function `split_random()`:

```{r}

# read the data from internet
oasis <- read.csv("https://raw.githubusercontent.com/aenneb/OASIS-beauty/master/means_per_image.csv")
oasis$string <- paste0("item", 1:nrow(oasis)) # is needed for lexOPS 

stims <- oasis %>%
  split_by(Valence_mean, 1:2.5 ~ 3.2:4.2 ~ 5.2:7) %>%
  control_for(Arousal_mean, -0.05:0.05) %>%
  generate(30) %>%
  long_format()

# sort by item id
stims <- stims[order(as.numeric(gsub("item", "", stims$string))), ]

# Compare descriptive statistics by set:
covariates <- c("Valence_mean", "Arousal_mean")
mean_sd_tab(
  stims[, covariates], 
  stims$condition
)

# plot the selection

# Illustrate final stimulus selection
was_selected <- oasis$string %in% stims$string
group <- rep(1, nrow(oasis))
group[was_selected] <- to_numeric(stims$condition) + 1

colors <- c("#a9a9a9", "#df536b", "#61d04f", "#2297e6")
cex <-  c(0.1, rep(1.1, 3))
pch <- c(4, 15, 17, 19)
plot(
  oasis[, c("Valence_mean", "Arousal_mean")],
  col = colors[group],
  cex = cex[group],
  pch = pch[group]
)

```

This is how we do it with `anticlust`:

```{r}


oasis <- within(oasis, {
  valence <- ifelse(Valence_mean <= 2.5, "Valence-low", NA)
  valence <- ifelse(Valence_mean > 3.2 & Valence_mean < 4.2, "Valence-neutral", valence)
  valence <- ifelse(Valence_mean > 5.2, "Valence-high", valence)
})

selected <- subset(oasis, !is.na(valence))

# Match the conditions based on covariates
selected$matches <- matching(
  selected$Arousal_mean, 
  match_between = selected$valence,
  match_extreme_first = FALSE
)

# Select the 25 best matches:
final_selection <- subset(selected, !is.na(matches) & matches <= 30)


# Check quality of the selection:
mean_sd_tab(
  subset(final_selection, select = c(Valence_mean, Arousal_mean)), 
  final_selection$valence
)


# Illustrate final stimulus selection
was_selected <- oasis$item %in% final_selection$item
group <- rep(1, nrow(oasis))
group[was_selected] <- to_numeric(final_selection$valence) + 1


colors <- c("#a9a9a9", "#df536b", "#61d04f", "#2297e6")
cex <-  c(0.1, rep(1.1, 3))
pch <- c(4, 15, 17, 19)
plot(
  oasis[, c("Valence_mean", "Arousal_mean")],
  col = colors[group],
  cex = cex[group],
  pch = pch[group]
)


```

## Example 2b - Include beauty as covariate

```{r}

stims <- oasis %>%
  split_by(Valence_mean, 1:4 ~ 4:5.1 ~ 5.1:7) %>%
  control_for(Arousal_mean, -0.1:0.1) %>%
  control_for(beauty_mean, -0.1:0.1) %>%
  generate(30) %>%
  long_format()

# sort by item id
stims <- stims[order(as.numeric(gsub("item", "", stims$string))), ]

# Compare descriptive statistics by set:
covariates <- c("Valence_mean", "Arousal_mean", "beauty_mean")
mean_sd_tab(
  stims[, covariates], 
  stims$condition
)

# Illustrate final stimulus selection
was_selected <- oasis$string %in% stims$string
group <- rep(1, nrow(oasis))
group[was_selected] <- to_numeric(stims$condition) + 1

colors <- c("#a9a9a9", "#df536b", "#61d04f", "#2297e6")
cex <-  c(0.1, rep(1.1, 3))
pch <- c(4, 15, 17, 19)
plot(
  oasis[, c("Valence_mean", "Arousal_mean", "beauty_mean")],
  col = colors[group],
  cex = cex[group],
  pch = pch[group]
)

```

This is how we do it with `anticlust`:

```{r}

oasis <- within(oasis, {
  valence <- ifelse(Valence_mean <= 4, "Valence-low", NA)
  valence <- ifelse(Valence_mean > 4 & Valence_mean <= 5.1, "Valence-neutral", valence)
  valence <- ifelse(Valence_mean > 5.1, "Valence-high", valence)
})

selected <- subset(oasis, !is.na(valence))

# Match the conditions based on covariates
oasis$matches <- matching(
  oasis[, c("Arousal_mean", "beauty_mean")], 
  match_between = oasis$valence,
  match_extreme_first = FALSE
)

# Select the 30 best matches:
final_selection <- subset(oasis, matches <= 30)

# Check quality of the selection:
mean_sd_tab(
  subset(final_selection, select = c(Valence_mean, Arousal_mean, beauty_mean)), 
  final_selection$valence
)

was_selected <- oasis$item %in% final_selection$item
group <- rep(1, nrow(oasis))
group[was_selected] <- to_numeric(final_selection$valence) + 1

plot(
  oasis[, c("Valence_mean", "Arousal_mean", "beauty_mean")],
  col = colors[group],
  cex = cex[group],
  pch = pch[group]
)

```

Again, the results are rather comparable.

## Limitations

Being the author of the `anticlust` package, I am naturally biased when 
comparing it to the `LexOPS` package. Still, I try to offer a balanced 
evaluation of both packages. And of course, this post only presents a 
non-exhaustive evaluation.

## More information

This post was too short to go into detail about the different 
algorithmic frameworks underlying the `LexOPS` and `anticlust` packages. 
A lot could be said about this, e.g., why it had to be expected that 
`anticlust` outperforms `LexOPS` in Example 2. For more background on 
the anticlustering methodology, check out the 
[preprint](https://psyarxiv.com/3razc/). However, note that some of the 
methodology presented in this post, especially min-max anticlustering, 
has not been thoroughly documented. I am currently working on that -- so 
stay tuned. The preprint describing the `LexOPS` package can be found 
[here](https://psyarxiv.com/7sudw) and the accompanying website is 
[here](https://jackedtaylor.github.io/LexOPSdocs/).

## References 

Papenberg, M., & Klau, G. W. (2019, October 30). Using anticlustering to 
partition a stimulus pool into equivalent parts. 
https://doi.org/10.31234/osf.io/3razc

Schaper, M. L., Kuhlmann, B. G., & Bayen, U. J. (2019). Metacognitive 
expectancy effects in source monitoring: Beliefs, in-the-moment 
experiences, or both? Journal of Memory and Language, 107, 95–110. 
https://doi.org/10.1016/j.jml.2019.03.009

Taylor, J. E., Beith, A., & Sereno, S. C. (2019, September 17). LexOPS: 
An R Package and User Interface for the Controlled Generation of Word 
Stimuli. https://doi.org/10.31234/osf.io/7sudw



---

Last updated: `r Sys.Date()`

### <a href="index.html">Back to the front page</a>

&nbsp;
