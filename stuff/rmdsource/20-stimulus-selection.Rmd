---
title: "Selecting experimental stimuli in `R`"
date: November 29, 2019
author: Martin Papenberg
output:
  html_document:
    df_print: kable
---

```{r, include = FALSE}

library(knitr)
library(dplyr)
knitr::opts_chunk$set(warning = FALSE) # echo = FALSE
options(scipen = 999, digits = 2)

knit_print.matrix = function(x, ...) {
    res = paste(c("", "", kable(x)), collapse = "\n")
    asis_output(res)
}
registerS3method("knit_print", "matrix", knit_print.matrix)

```

I spent the better part of the last year working on anticlustering, a 
methodology to select stimuli for experiments in psychology. The work 
culminated in the the `R` package 
[`anticlust`](https://github.com/m-Py/anticlust) and the manuscript 
»[Using anticlustering to partition a stimulus pool into equivalent 
parts](https://psyarxiv.com/3razc/)« 

I was made aware of another `R` package that was also designed to select 
stimuli for experiments: 
[`LexOPS`](https://github.com/JackEdTaylor/LexOPS/). Interestingly, both 
packages were first uploaded to Github on October 25, 2018.

In this post I compare the results of the two packages by applying each 
to three data sets that vary in size from very large to rather small.

## Example 1: Large data set `lexops`

First, let's load the packages:

```{r}
library(LexOPS)
library(anticlust)
```

We start by using a data set that is built into the `lexops`:

```{r}
head(lexops)
nrow(lexops)
```

We now reproduce the the first example on the [package 
website](https://jackedtaylor.github.io/LexOPSdocs/the-generate-pipeline.html).
In this example, we extract two sets of stimuli each having 25 elements 
from the entire pool of stimuli. The stimuli should differ on 
`CNC.Brysbaert` but be similar on `Length` and `Zipf.SUBTLEX_UK`; for 
more information on the variables we use for stimulus selection, follow 
the link above. 

```{r}

stim <- lexops %>%
  subset(PK.Brysbaert >= 0.9) %>%
  split_by(CNC.Brysbaert, 1:2 ~ 4:5) %>%
  split_by(BG.SUBTLEX_UK, 0:0.003 ~ 0.009:0.013) %>%
  control_for(Length, 0:0) %>%
  control_for(Zipf.SUBTLEX_UK, -0.2:0.2) %>%
  generate(n = 25) %>%
  long_format()
```

We obtain a table like this:

```{r}
head(stim)
```

To validate the usefulness of the output, let's check out the means and 
standard deviations of the variables that were considered, using the 
function `mean_sd_tab()` from the `anticlust` package.

```{r}
# Compare descriptive statistics by set:
mean_sd_tab(
  stim[, c("CNC.Brysbaert", "BG.SUBTLEX_UK", "Length", "Zipf.SUBTLEX_UK")], 
  stim$condition
)
```

In brackets, we have the standard deviations by set, and before that the 
mean values. As shown, the word sets are quite well balanced on `Length` 
and `Zipf.SUBTLEX_UK`, and quite dissimilar with regard to 
`CNC.Brysbaert` and `BG.SUBTLEX_UK`. That is good, because it is what we 
want!

Let's do the same using the `anticlust` package:[^1]

[^1]: Currently, you need to install the development version for this 
functionality, see the vignette 
[here](../anticlust/stimulus-selection.html)

```{r}

# First, I subset the data and recode variables
stim <- subset(lexops, PK.Brysbaert >= 0.9)
# Code boundaries for the independent variables
stim <- within(lexops, {
  CNC <- ifelse(CNC.Brysbaert >= 1 & CNC.Brysbaert <= 2, "CNC-low", NA)
  CNC <- ifelse(CNC.Brysbaert >= 4 & CNC.Brysbaert <= 5, "CNC-high", CNC)
  BG  <- ifelse(BG.SUBTLEX_UK >= 0 & BG.SUBTLEX_UK <= 0.003, "BG-low", NA)
  BG  <- ifelse(BG.SUBTLEX_UK >= 0.009 & BG.SUBTLEX_UK <= 0.013, "BG-high", BG)
})

# Remove NA values
stim <- subset(stim, !is.na(CNC) & !is.na(BG) & !is.na(Length) & !is.na(Zipf.SUBTLEX_UK))

# Match the conditions based on covariates
stim$matches <- matching(
  subset(stim, select = c(Length, Zipf.SUBTLEX_UK)), 
  groups = subset(stim, select = c(BG, CNC))
)

# Only select full matches
selection <- subset(stim, !is.na(matches))

# Matches are numbered by achieved similarity. Good matches:
subset(selection, matches == 1, c(Length, Zipf.SUBTLEX_UK, BG, CNC, matches))
subset(selection, matches == 2, c(Length, Zipf.SUBTLEX_UK, BG, CNC, matches))

# Select the 25 best matches:
final_selection <- subset(selection, matches < 26)


# Check quality of the selection:
mean_sd_tab(
  final_selection[, c("CNC.Brysbaert", "BG.SUBTLEX_UK", "Length", "Zipf.SUBTLEX_UK")], 
  paste(final_selection$BG, final_selection$CNC)
)

```

The `anticlust` package uses a methodology called 
min-max-anticlustering[^minmax]---it maximizes differerences with regard 
to independent variables while simultaneously minizimizing differences 
with regard to covariates. 

[^minmax]: This method still has to be documented thoroughly -- I am 
working on it.

The results show that the the word sets are quite well balanced on 
`Length` and `Zipf.SUBTLEX_UK`, while they are different with regard to 
`CNC.Brysbaert` and `BG.SUBTLEX_UK`. It seems that `anticlust` ensured 
covariate similarity with regard to `Zipf.SUBTLEX_UK` a little more 
strictlythan `LexOPS`, but overall the results for both packages are 
very similar.

Note that the `LexOPS` package was faster for this large data set ($N$ = 
29783) than the `anticlust` package (< 1 sec for `LexOPS` vs. about 1 
min for `anticlust` on my PC). However, both running times are well 
acceptable for everyday use.

## Example 2: Medium sized data set `oasis`

Next, I use a stimulus set describing 900 images on the dimensions 
valence, arousal and beauty (I also use this data set in the 
[`anticlust` vignette for stimulus 
selection](../anticlust/stimulus-selection.html)). I select three sets 
each consisting of 40 stimuli. I have a slightly different goal than 
before: I wish to create sets that are as similar as possible with 
regard to **all** variables under considerations; I do not vary an 
independent variable between sets. This is what the original 
anticlustering accomplishes---it creates sets that are as similar as 
possible. 

Again, I start with the `LexOPS` package. To ensure that three sets are 
created without having an independent variable, I have to use the 
function `split_random()`:

```{r}
# read the data from internet
oasis <- read.csv("https://raw.githubusercontent.com/aenneb/OASIS-beauty/master/means_per_image.csv")
oasis$string <- paste0("item", 1:nrow(oasis)) # is needed for lexOPS 

stims <- oasis %>%
  split_random(3) %>%
  control_for(Valence_mean, -0.5:0.5) %>%
  control_for(Arousal_mean, -0.5:0.5) %>%
  control_for(beauty_mean, -0.5:0.5) %>%
  generate(40) %>%
  long_format()

# Compare descriptive statistics by set:
covariates <- c("Valence_mean", "Arousal_mean", "beauty_mean")
mean_sd_tab(
  stims[, covariates], 
  stims$condition
)
```

For this application, `anticlust` can do much better: 

```{r}

oasis$matches <- matching(
  oasis[, covariates], 
  p = 3
)

# Matches are numbered by achieved similarity. Good matches:
subset(oasis, matches == 1, covariates)
subset(oasis, matches == 2, covariates)

# Select the 40 best matches:
selection <- subset(oasis, matches <= 40)

# do anticlustering for optimization
selection$ac <- anticlustering(
  selection[, covariates],
  K = 3,
  categories = selection$matches
)

mean_sd_tab(
  selection[, covariates], 
  selection$ac
)

```

## Limitations

Being the author of the `anticlust` package, I am naturally biased when 
comparing it to the `LexOPS` package. Still, I try to offer a balanced 
evaluation of both packages. And of course, this post only presents a 
non-exhaustive evaluation.

## Conclusions

Advantages for `anticlust`:

- seems to ensure covariate similarity better on a group level
- can be used on small data sets; no subset selection is necessary
- can balanced a categorical variable between sets
- most important (IMHO): algorithmic optimization of (dis)similarity; 
  `LexOPS` takes as arguments specifications with regard to the allowed
  dissimilarity and then checks if the requirements can be fulfilled. 
  `anticlust` will just try to produce the best result it can get without
  requiring user specification

Disadvantages for `anticlust`:

- Was slower for the very large data set than `LexOPS`
- does not enable individual matching of stimuli, optimizes group level 
similarity

Advantages for `LexOPS`:

- can implement more complex designs 
- individual matches are possible (e.g., for each word you can have 
another word with the same length)
- has a shiny app, including functionality for visualization---when 
selecting stimuli, visualizations of the variables can be extremely 
helpful, (also see my [vignette](../anticlust/stimulus-selection.html))
- fine grained control via the `tolerance` argument with regard to 
individual matches; but it is also difficult to know how to best make use 
of this option

Disadvantages for `LexOPS`:

- does not always find solutions for small data sets
- cannot partition a complete item pool into subsets (this is what
`anticlust` was originally designed to do)
- cannot balance categorical variable between sets (?)

To conclude, I think that both `R` packages for stimulus selection are 
useful and have a right to exist (hell, for most tasks, there is a far 
vaster amount of `R` packages available). Researchers interested in 
specifying contraints regarding individual matches between stimuli may 
be interested in using the `LexOPS` package. When researchers just want 
to balance similarity on group level, the `anticlust` package seems to 
have an edge, especially when the available item pool is not huge.

## More information

This post was too short to go into detail about the different 
algorithmic frameworks underlying the `LexOPS` and `anticlust` packages. 
A lot could be said about this, e.g., why it had to be expected that 
`anticlust` outperforms `LexOPS` in Example 2. For more background on 
the anticlustering methodology, check out the 
[preprint](https://psyarxiv.com/3razc/). However, note that some of the 
methodology presented in this post, especially min-max anticlustering, 
has not been thoroughly documented. I am currently working on that -- so 
stay tuned. The preprint describing the `LexOPS` package can be found 
[here](https://psyarxiv.com/7sudw) and the accompanying website is 
[here](https://jackedtaylor.github.io/LexOPSdocs/).

## References 

Papenberg, M., & Klau, G. W. (2019, October 30). Using anticlustering to 
partition a stimulus pool into equivalent parts. 
https://doi.org/10.31234/osf.io/3razc

Schaper, M. L., Kuhlmann, B. G., & Bayen, U. J. (2019). Metacognitive 
expectancy effects in source monitoring: Beliefs, in-the-moment 
experiences, or both? Journal of Memory and Language, 107, 95–110. 
https://doi.org/10.1016/j.jml.2019.03.009

Taylor, J. E., Beith, A., & Sereno, S. C. (2019, September 17). LexOPS: 
An R Package and User Interface for the Controlled Generation of Word 
Stimuli. https://doi.org/10.31234/osf.io/7sudw



---

Last updated: `r Sys.Date()`

### <a href="index.html">Back to the front page</a>

&nbsp;
