---
title: "What Bayes factor should you expect?"
date: December 18, 2017
author: Martin Papenberg


bibliography: "./lit/lit.bib"
csl: "./lit/apa.csl"

---

The usage of Bayesian statistics, and in particular the usage of Bayes
factors is on the rise in Psychology. Bayes factors have been advocated
as an alternative to statistical null hypothesis significance testing
relying on *p*-values [@wagenmakers2017; xx]. They quantify the relative
evidence that data provide for two different hypotheses. As a prominent
application in Psychology, several "default" Bayes factors have been
proposed that compare an alternative hypothesis assuming an effect
(e.g. there is a difference between two means) to a null hypothesis
assuming no effect (e.g. there is no difference between two means). Such
Bayes factors quantify how much better a specified alternative
hypothesis describes the data than the null hypothesis [^1]. For
example, when obtaining a Bayes factor of size 5, the data are 5 times
more likely under the alternative hypothesis than under the null
hypothesis; you may say that the data favor the alternative hypothesis
by a factor of 5 [^2]. I will not give a detailed introduction to Bayes
factors here, there is a variety treatments on Bayes factors, including
the mathematical and philosophical basics [e.g., ...], how to compute
them [e.g., ...], how to interpret them [e.g., ...] and how they differ
from *p*-values [e.g., ...].

The general appraisal of Bayes factors seems to reach from "*will save
statistical inference in Psychology from evil p-values*" to "*dangerous
statistic that will lead to bogus interpretations of data*". However one
may think of Bayes factors, given their increasing occurrence in
Psychological research it is probably useful to know how they behave
under different settings. In this post I therefore describe what Bayes
factors you should expect when varying the sample size and effect
size. As is done often, I will stick to the example of the independent
sample *t*-test that compares two means, and I will use the "default"
Bayes factor proposed by @rouder2009, which is implemented in the R
package BayesFactor [@R-BayesFactor] [^3]. Note that for this reason my
evaluation of Bayes factors is limited to this specific model.

## The default Bayes factor

## The distribution of Bayes factors

The following plot illustrates the distribution of Bayes factors for
different sample sizes and effect sizes *d* = 0 (meaning that the null
hypothesis is true), *d* = 0.2 (a small effect), *d* = 0.5 (a medium
effect) and *d* = 0.8 (a large effect). What I mean with distribution is
explained below. Note that null and small effect share the same scaling
of the y-axis; medium and large effect also share the same scaling but
this scaling is different to the scaling of the y-axis of null and small
effect (simply because the values of the Bayes factor differ very
strongly by effect size). The data were generated in a simulation
assuming normally distributed scores (*M* = 0 for one group and *M* =
*d* for the other group; *SD* = 1 for both groups).

So, what do the plots mean? Each plot illustrates the 20%, 50%, and 80%
quantiles of the Bayes factors that you obtain for different sample
sizes. Given a sample size and a effect size, 80% of all Bayes factors
will be smaller than the corresponding green dot indicates; 50% will be
smaller than the red dot, 20% will be smaller than the black dot. What
does this tell us? Assume we are planning a study to compare two
independent means and we want to use the default Cauchy Bayes factor. In
this case we are interested in the number of participants we need to
obtain meaningful results.


```{r,  message = FALSE, warning = FALSE, echo = FALSE, results="hide", fig.width = 8}
# set knitr options
knitr::opts_chunk$set(message=FALSE, echo=FALSE, warning=FALSE)

source("./rsource/functions.R")

get(load("./data/defBF.data")) # check out names(defBF)

quants <- c(0.2, 0.5, 0.8)
quantiles_02 <- BF_quantiles(defBF$BF02, quants)
quantiles_0  <- BF_quantiles(defBF$BF0,  quants)

## plot null effect and small effect d = 0.2
par(mfrow=c(1,2))
plot_BF_quantiles(quantiles_0, c(1/10, 1/3, 1, 3, 10),
                  ylim=c(-3, 4), main="d = 0 (null effect)", axis="log")
legend("topleft", legend=paste0(c(80, 50, 20), "% of all BFs are smaller"), pch = 3,
       col = 3:1, bty="n")
plot_BF_quantiles(quantiles_02, c(1/10, 1/3, 1, 3, 10),
                  ylim=c(-3, 4), main="d = 0.2 (small effect)", axis="standard")
```

```{r,  message = FALSE, warning = FALSE, echo = FALSE, results="hide", fig.width = 8}

quantiles_08 <- BF_quantiles(defBF$BF08, quants)
quantiles_05 <- BF_quantiles(defBF$BF05, quants)

## plot medium effect (d = 0.5) and large effect (d = 0.8)
par(mfrow=c(1,2))
plot_BF_quantiles(quantiles_05, c(1/10, 1/3, 1, 3, 10),
                  ylim=c(-3, 6), main="d = 0.5 (medium effect)", axis="log")
plot_BF_quantiles(quantiles_08, c(1/3, 1, 3, 10),
                  ylim=c(-3, 6), main="d = 0.8 (large effect)", axis="standard")
legend("bottomright", legend=paste0(c(80, 50, 20), "% of all BFs are smaller"), pch = 3,
       col = 3:1, bty="n")
```

There are other treatments relevant to this question:

Sequential Hypothesis Testing With Bayes Factors: Efficiently Testing
Mean Differences (SchÃ¶nbrodt, 2015) 

Dance of the Bayes factors (Lakens, 2016)
http://daniellakens.blogspot.de/2016/07/dance-of-bayes-factors.html

&nbsp;

### <a href="index.html">Back to the front page</a>

&nbsp;

# References

[^1]: In general it is not necessary that one of the competing
hypotheses is a null hypothesis.

[^2]: However, you may not say that the alternative hypothesis is 5
times more likely than the null hypothesis.

[^3]: This is also the Bayes factor used in the statistics program JASP
when doing the Bayesian *t*-test.

